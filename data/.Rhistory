package.installs(e1071)
install.packages(e1071)
install.packages('e1071')
library(e1071)
svm_fit<-svm(y~x1+x2+x3,data=training)
svm_predictions<-predict(svm_fit,newdata=testing)
error<-sqrt((sum((testing$y-svm_predictions)^2))/nrow(testing))
error
predictions<-(svm_predictions+rf_predictions)/2
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
predictions<-(svm_predictions*2+rf_predictions)/3
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
install.packages("nnet")
library("nnet")
ird <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
species = factor(c(rep("s",50), rep("c", 50), rep("v", 50))))
ir.nn2 <- nnet(species ~ ., data = ird, subset = samp, size = 2, rang = 0.1,
decay = 5e-4, maxit = 200)
table(ird$species[-samp], predict(ir.nn2, ird[-samp,], type = "class"))
# use half the iris data
ir <- rbind(iris3[,,1],iris3[,,2],iris3[,,3])
targets <- class.ind( c(rep("s", 50), rep("c", 50), rep("v", 50)) )
samp <- c(sample(1:50,25), sample(51:100,25), sample(101:150,25))
ir1 <- nnet(ir[samp,], targets[samp,], size = 2, rang = 0.1,
decay = 5e-4, maxit = 200)
test.cl <- function(true, pred) {
true <- max.col(true)
cres <- max.col(pred)
table(true, cres)
}
test.cl(targets[-samp,], predict(ir1, ir[-samp,]))
predict(ir1, ir[-samp,])
View(ir)
View(ird)
View(targets)
View(ir)
nnet.fit <- nnet(medv/50 ~ ., data=BostonHousing, size=2)
data(BostonHousing)
nnet.fit <- nnet(medv/50 ~ ., data=BostonHousing, size=2)
irData <- iris
View(irData)
irData <- iris
positions <- sample(nrow(irData),size=floor((nrow(train)/4)*3))
training<- irData[positions,]
testing<- irData[-positions,]
positions <- sample(nrow(irData),size=floor((nrow(irData)/4)*3))
training<- irData[positions,]
testing<- irData[-positions,]
View(testing)
View(training)
nnetMod <- nnet(Sepal.Length ~ ., data=irData, size=2)
result <- predict(nnetMod,testing)
View(result)
nnetMod <- nnet(Sepal.Length/50 ~ ., data=irData, size=2)
result <- predict(nnetMod,testing)*50
View(result)
fix(nnetMod)
result <- round((predict(nnetMod,testing)*50),6)
predict(ir1, ir[-samp,])
nnetMod <- nnet("Sepal.Length" ~ ., data=irData, size=2)
setwd("C:/Users/thiak/Documents/kx/molecule/data/varsImpt")
Nfiles=15
for ( i in 1:Nfiles ) {
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>1)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptRF_", i, ".csv", sep='')
RFImpt<-read.csv(varsFile)
allImpt <-merge(GBMImpt,RFImpt,sort=FALSE)
setwd("C:/Users/thiak/Documents/kx/molecule/data/varsImpt")
Nfiles=15
for ( i in 1:Nfiles ) {
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>1)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptRF_", i, ".csv", sep='')
RFImpt<-read.csv(varsFile)
allImpt <-merge(GBMImpt,RFImpt,sort=FALSE)
varsFile <- paste("varsImptAllGLM_", i, ".csv", sep='')
write.csv(allImpt,varsFile, quote=TRUE, row.names=FALSE)
}
setwd("C:/Users/thiak/Documents/kx/molecule/data/varsImpt")
Nfiles=15
for ( i in 1:Nfiles ) {
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>1)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptRF_", i, ".csv", sep='')
RFImpt<-read.csv(varsFile)
allImpt <-merge(GBMImpt,RFImpt,sort=FALSE)
varsFile <- paste("varsImptAllGLM_", i, ".csv", sep='')
write.csv(allImpt,varsFile, quote=TRUE, row.names=FALSE)
}
setwd("C:/Users/thiak/Documents/kx/molecule/data/varsImpt")
Nfiles=15
for ( i in 1:Nfiles ) {
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.5)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptRF_", i, ".csv", sep='')
RFImpt<-read.csv(varsFile)
allImpt <-merge(GBMImpt,RFImpt,sort=FALSE)
varsFile <- paste("varsImptAllGLM_", i, ".csv", sep='')
write.csv(allImpt,varsFile, quote=TRUE, row.names=FALSE)
}
fix(GBMImpt)
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.1)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
fix(GBMImpt)
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.3)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.4)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.2)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
setwd("C:/Users/thiak/Documents/kx/molecule/data/varsImpt")
Nfiles=15
for ( i in 1:Nfiles ) {
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.2)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptRF_", i, ".csv", sep='')
RFImpt<-read.csv(varsFile)
allImpt <-merge(GBMImpt,RFImpt,sort=FALSE)
varsFile <- paste("varsImptAllGLM_", i, ".csv", sep='')
write.csv(allImpt,varsFile, quote=TRUE, row.names=FALSE)
}
#takes 8hr to complete
setwd("C:/Users/thiak/Documents/kx/molecule/data")
library(foreach)
library(doSNOW)
Nfiles = 15
cluster <-makeCluster(3, type = "SOCK")
registerDoSNOW(cluster)
setMKLthreads(1)
setwd("C:/Users/thiak/Documents/kx/molecule/data/varsImpt")
Nfiles=15
for ( i in 1:Nfiles ) {
varsFile <- paste("varsImptGBMScore_", i, ".csv", sep='')
GBMImpt<-read.csv(varsFile)
GBMImpt<-subset(GBMImpt,GBMImpt$importance>0.2)
GBMImpt<-c("MOLECULE","Act",as.character(GBMImpt[,1]))
varsFile <- paste("varsImptRF_", i, ".csv", sep='')
RFImpt<-read.csv(varsFile)
allImpt <-merge(GBMImpt,RFImpt,sort=FALSE)
varsFile <- paste("varsImptAllGLM_", i, ".csv", sep='')
write.csv(allImpt,varsFile, quote=TRUE, row.names=FALSE)
}
setwd("C:/Users/thiak/Documents/kx/molecule/data")
i=7
varFileIn <- paste("varsImpt/varsImptAllGLM_", i, ".csv", sep='')
VarsToKeep=as.character(read.csv(varFileIn)[,1])
trainFileIn <- paste("ACT", i, "_competition_training.xdf", sep='')
train <- rxReadXdf(file=trainFileIn,varsToKeep=VarsToKeep)
testFileIn <- paste("ACT", i, "_competition_test.xdf", sep='')
test <- rxReadXdf(file=testFileIn)
#dont need the firest two variable (molecule and ACT)
VarsToKeep<-VarsToKeep[3:length(VarsToKeep)]
VarsToKeepSquare<-paste("I(",VarsToKeep,"^2)",sep='')
VarsToKeep<- c(VarsToKeep,VarsToKeepSquare)
eqn <- as.formula(paste("Act ~",paste(VarsToKeep,collapse = "+"),sep=''))
fix(eqn)
predictions<-foreach(1:500,.combine=cbind) %dopar%{
training_positions <- sample(nrow(train), size=floor((nrow(train)*0.9)),
replace = FALSE)
train_pos<-1:nrow(train) %in% training_positions
glmMod<-rxGlm(eqn, train[train_pos,])
rxPredict(glmMod,test)
}
eqn <- as.formula(paste("Act ~",paste(VarsToKeep,collapse = "+"),sep=''))
predictions<-foreach(1:500,.combine=cbind) %dopar%{
training_positions <- sample(nrow(train), size=floor((nrow(train)*0.9)),
replace = FALSE)
train_pos<-1:nrow(train) %in% training_positions
glmMod<-rxGlm(eqn, train[train_pos,])
rxPredict(glmMod,test)
}
eqn <- as.formula(paste("Act ~",paste(VarsToKeep,collapse = "+"),sep=''))
predictions<-foreach(1:50,.combine=cbind) %dopar%{
training_positions <- sample(nrow(train), size=floor((nrow(train)*0.9)),
replace = FALSE)
train_pos<-1:nrow(train) %in% training_positions
glmMod<-rxGlm(eqn, train[train_pos,])
rxPredict(glmMod,test)
}
result<-rowMeans(predictions)
cluster <-makeCluster(3, type = "SOCK")
registerDoSNOW(cluster)
setMKLthreads(1)
eqn <- as.formula(paste("Act ~",paste(VarsToKeep,collapse = "+"),sep=''))
predictions<-foreach(1:50,.combine=cbind) %dopar%{
training_positions <- sample(nrow(train), size=floor((nrow(train)*0.9)),
replace = FALSE)
train_pos<-1:nrow(train) %in% training_positions
glmMod<-rxGlm(eqn, train[train_pos,])
rxPredict(glmMod,test)
}
result<-rowMeans(predictions)
fix(result)
View(predictions)
fix(result)
fix(VarsToKeep)
fix(VarsToKeepSquare)
setwd("C:/Users/thiak/Documents/kx/molecule")
responses <- read.csv('example_data.csv')
View(responses)
fit2 <- lm(responses$dog.love ~ responses$vanilla.love
+ I(responses$vanilla.love^2) + responses$strawberry.love
+ I(responses$strawberry.love^2) + responses$chocolate.love
+ I(responses$chocolate.love^2))
summary(fit2)
-357.444 + 72.444 * responses$vanilla.love
- 6.111 * responses$vanilla.love^2
+ 59.5 * responses$strawberry.love
- 5.722 * responses$strawberry.love^2
+ 7 * responses$chocolate.love
-357.444 + 72.444 * responses$vanilla.love - 6.111 * responses$vanilla.love^2 + 59.5 * responses$strawberry.love - 5.722 * responses$strawberry.love^2 + 7 * responses$chocolate.love
eqn <- as.formula(paste("Act ~",paste(VarsToKeep,collapse = "+"),sep=''))
predictions<-foreach(1:50,.combine=cbind) %dopar%{
training_positions <- sample(nrow(train), size=floor((nrow(train)*0.9)),
replace = FALSE)
train_pos<-1:nrow(train) %in% training_positions
glmMod<-m(eqn, train[train_pos,])
Predict(glmMod,test)
}
result<-rowMeans(predictions)
eqn <- as.formula(paste("Act ~",paste(VarsToKeep,collapse = "+"),sep=''))
predictions<-foreach(1:50,.combine=cbind) %dopar%{
training_positions <- sample(nrow(train), size=floor((nrow(train)*0.9)),
replace = FALSE)
train_pos<-1:nrow(train) %in% training_positions
glmMod<-lm(eqn, train[train_pos,])
predict(glmMod,test)
}
result<-rowMeans(predictions)
fix(result)
View(predictions)
postal<-1:999999
sg<-"singapore"
postal<-list(1:999999)
postal<-data.frame(1:999999)
View(postal)
library(sp)
data(meuse.grid)
HexPts <- spsample(meuse.grid, type = "hexagonal", cellsize = 200)
spplot(meuse.grid["dist"], sp.layout = list("sp.points", HexPts, col = 1))
HexPols <- HexPoints2SpatialPolygons(HexPts)
df <- as.data.frame(meuse.grid)[overlay(meuse.grid, HexPts), ]
HexPolsDf<-SpatialPolygonsDataFrame(HexPols, df, match.ID = FALSE)
spplot(HexPolsDf["dist"])
library(sp)
data(meuse.grid)
HexPts <- spsample(meuse.grid, type = "hexagonal", cellsize = 200)
library("sp")
data(meuse.grid)
gridded(meuse.grid) = ~x + y
HexPts <- spsample(meuse.grid, type = "hexagonal", cellsize = 200)
spplot(meuse.grid["dist"], sp.layout = list("sp.points", HexPts, col = 1))
HexPols <- HexPoints2SpatialPolygons(HexPts)
df <- as.data.frame(meuse.grid)[overlay(meuse.grid, HexPts),]
HexPolsDf <- SpatialPolygonsDataFrame(HexPols, df, match.ID = FALSE)
spplot(HexPolsDf["dist"])
x<-as.data.frame(HexPolsDf)
View(x)
y<-muese
y<-muese.grid
y<-data(muese.grid)
y<-data(meuse.grid)
View(meuse.grid)
require(sp)
download.file("http://www.spc.noaa.gov/gis/svrgis/Tornado_touchdown_points.zip","Tornado_touchdown_points.zip",mode="wb")
require(maptools)
library(maptools)
library(rgeos)
library(rgdal)
require(sp)
#define boundry to draw hexagon
baseCRS<-CRS("+proj=longlat +ellps=WGS84")
LambertCRS<-" +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-100"
coords1<-matrix(c(-125,20, -125,50, -66,50 ,-66,20,-125,20),
ncol=2, byrow=TRUE)
# coords=project(coords1,LambertCRS)
pg=Polygon(coords) #rectangle boundry
coords=coords1
pg=Polygon(coords) #rectangle boundry
#Sample hexagonal points, convert to polygons
HexPts=spsample(pg, type="hexagonal", n=2000, offset=c(0,0))
HexPols = HexPoints2SpatialPolygons(HexPts)
#transform back into lon, lat coordinates
HexPols<-spTransform(HexPols,baseCRS)
hexNumber<-data.frame(1:length(HexPols))
names(hexNumber)<-"hexNumber"
writeSpatialShape(SpatialPolygonsDataFrame(HexPols,hexNumber,match.ID = FALSE),"hexagon")
#define boundry to draw hexagon
baseCRS<-CRS("+proj=longlat +ellps=WGS84")
LambertCRS<-" +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-100"
coords1<-matrix(c(-125,20, -125,50, -66,50 ,-66,20,-125,20),
ncol=2, byrow=TRUE)
coords=project(coords1,LambertCRS)
pg=Polygon(coords) #rectangle boundry
#Sample hexagonal points, convert to polygons
HexPts=spsample(pg, type="hexagonal", n=2000, offset=c(0,0))
HexPols = HexPoints2SpatialPolygons(HexPts)
# proj4string(HexPols)<-LambertCRS
#transform back into lon, lat coordinates
HexPols<-spTransform(HexPols,baseCRS)
hexNumber<-data.frame(1:length(HexPols))
names(hexNumber)<-"hexNumber"
writeSpatialShape(SpatialPolygonsDataFrame(HexPols,hexNumber,match.ID = FALSE),"hexagon")
#define boundry to draw hexagon
baseCRS<-CRS("+proj=longlat +ellps=WGS84")
LambertCRS<-" +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-100"
coords1<-matrix(c(-125,20, -125,50, -66,50 ,-66,20,-125,20),
ncol=2, byrow=TRUE)
# coords=project(coords1,LambertCRS)
# pg=Polygon(coords) #rectangle boundry
pg=Polygon(coords1)
#Sample hexagonal points, convert to polygons
HexPts=spsample(pg, type="hexagonal", n=2000, offset=c(0,0))
HexPols = HexPoints2SpatialPolygons(HexPts)
proj4string(HexPols)<-LambertCRS
#transform back into lon, lat coordinates
HexPols<-spTransform(HexPols,baseCRS)
hexNumber<-data.frame(1:length(HexPols))
names(hexNumber)<-"hexNumber"
writeSpatialShape(SpatialPolygonsDataFrame(HexPols,hexNumber,match.ID = FALSE),"hexagon")
baseCRS<-CRS("+proj=longlat +ellps=WGS84")
LambertCRS<-" +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-100"
coords1<-matrix(c(-125,20, -125,50, -66,50 ,-66,20,-125,20),
ncol=2, byrow=TRUE)
coords=project(coords1,LambertCRS)
pg=Polygon(coords) #rectangle boundry
#Sample hexagonal points, convert to polygons
HexPts=spsample(pg, type="hexagonal", n=2000, offset=c(0,0))
HexPols = HexPoints2SpatialPolygons(HexPts)
proj4string(HexPols)<-LambertCRS
#transform back into lon, lat coordinates
HexPols<-spTransform(HexPols,baseCRS)
hexNumber<-data.frame(1:length(HexPols))
names(hexNumber)<-"hexNumber"
writeSpatialShape(SpatialPolygonsDataFrame(HexPols,hexNumber,match.ID = FALSE),"hexagon")
library(maptools)
library(rgeos)
library(rgdal)
require(sp)
#define boundry to draw hexagon
baseCRS<-CRS("+proj=longlat +ellps=WGS84")
LambertCRS<-" +proj=lcc +lat_1=60 +lat_2=30 +lon_0=-100"
coords1<-matrix(c(-125,20, -125,50, -66,50 ,-66,20,-125,20),
ncol=2, byrow=TRUE)
coords=project(coords1,LambertCRS)
pg=Polygon(coords) #rectangle boundry
#Sample hexagonal points, convert to polygons
HexPts=spsample(pg, type="hexagonal", n=2000, offset=c(0,0))
HexPols = HexPoints2SpatialPolygons(HexPts)
proj4string(HexPols)<-LambertCRS
#transform back into lon, lat coordinates
HexPols<-spTransform(HexPols,baseCRS)
hexNumber<-data.frame(1:length(HexPols))
names(hexNumber)<-"hexNumber"
writeSpatialShape(SpatialPolygonsDataFrame(HexPols,hexNumber,match.ID = FALSE),"hexagon")
install.packages("ape")
library(ape)
tr <- rtree(30)
x <- rnorm(30)
## weights w[i,j] = 1/d[i,j]:
w <- 1/cophenetic(tr)
## set the diagonal w[i,i] = 0 (instead of Inf...):
diag(w) <- 0
Moran.I(x, w)
Moran.I(x, w, alt = "l")
Moran.I(x, w, alt = "g")
Moran.I(x, w, scaled = TRUE) # usualy the same
View(w)
x<-Moran.I(x, w)
install.packages("spdep")
library(spdep)
data(afcon)
oid <- order(afcon$id)
resI <- localmoran(afcon$totcon, nb2listw(paper.nb))
printCoefmat(data.frame(resI[oid,], row.names=afcon$name[oid]),
check.names=FALSE)
hist(resI[,5])
resI <- localmoran(afcon$totcon, nb2listw(paper.nb),
p.adjust.method="bonferroni")
printCoefmat(data.frame(resI[oid,], row.names=afcon$name[oid]),
check.names=FALSE)
hist(resI[,5])
totcon <-afcon$totcon
is.na(totcon) <- sample(1:length(totcon), 5)
totcon
resI.na <- localmoran(totcon, nb2listw(paper.nb), na.action=na.exclude,
zero.policy=TRUE)
if (class(attr(resI.na, "na.action")) == "exclude") {
print(data.frame(resI.na[oid,], row.names=afcon$name[oid]), digits=2)
} else print(resI.na, digits=2)
resG <- localG(afcon$totcon, nb2listw(include.self(paper.nb)))
print(data.frame(resG[oid], row.names=afcon$name[oid]), digits=2)
x<-str(resI.na)
str(resI)
printCoefmat(data.frame(resI[oid,], row.names=afcon$name[oid]),
check.names=FALSE)
View(afcon)
x<-paper.nb
x<-data.frame(paper.nb)
library(raster)
r  <-  raster(nrows=10,  ncols=10)
r[]  <-  1:ncell(r)
Moran(r) #this is the global index of autocorrelation
x1  <-  MoranLocal(r) #local measure of autocorr as a raster object that can be plotted
plot(x1) #this will plot the autocorrelation raster results
library(maptools)
library(rgeos)
library(rgdal)
library(sp)
library(leafletR)
library(classInt)
setwd("~/Documents/datascience SG/presentation at RUGs/kaggle_data/")
source("../baseFunctions.R")
Hex <- readShapeSpatial("Hex", proj4string=CRS("+proj=longlat +datum=WGS84"))
setwd("~/Documents/datascience SG/MusingsOfKaggler/RCode/data")
source("../baseFunctions.R")
trainData<-read.csv("train.csv")
#classify by cities based on lat long
trainData$longitudeCut<-trunc(trainData$longitude)
trainData$city<-""
trainData$city[trainData$longitudeCut=="-77"]<-"richmond"
trainData$city[trainData$longitudeCut=="-72"]<-"new_haven"
trainData$city[trainData$longitudeCut=="-87"]<-"chicargo"
trainData$city[trainData$longitudeCut=="-122"]<-"oakland"
trainData$city<-as.factor(trainData$city)
coltoKeep<-c("latitude","longitude","num_votes","num_comments","num_views","source","tag_type","city")
trainData<-trainData[,coltoKeep]
trainData_map<-as.matrix(trainData[,c("longitude","latitude")])
trainData_map<-SpatialPointsDataFrame(trainData_map,trainData[,c("num_votes","num_comments","num_views","source","tag_type","city")]
,proj4string = baseCRS)
# #write shp file
# writeSpatialShape(trainData_map,"trainData_map")
#generate hexagonal grid by region
regionPt<-read.csv("regionPoints.csv")
oakland_PtData<-generateHex(regionPt[regionPt$region=="oakland",])
new_haven_PtData<-generateHex(regionPt[regionPt$region=="new_haven",])
richmond_PtData<-generateHex(regionPt[regionPt$region=="richmond",])
chicargo_PtData<-generateHex(regionPt[regionPt$region=="chicargo",])
Hex<-rbind(oakland_PtData,new_haven_PtData,richmond_PtData,chicargo_PtData)
# #write shp file
# writeSpatialShape(Hex,"baseHexagon")
#point in polygon analysis, count number of trainData pts in each hex
# remove the polygons with no data pts in them
HexPt<-over(trainData_map,Hex)
DataTemp<-data.frame(trainData_map,HexPt)
DataTemp<-data.table(DataTemp)
HexPt<-DataTemp[,list(count=length(num_votes),avgVote=round(mean(num_votes),2),
avgComment=round(mean(num_comments),2),avgView=round(mean(num_views),2)),by=hexNumber]
Hex<-merge(Hex,HexPt,by="hexNumber",all.x=FALSE)
# #write shp file
# writeSpatialShape(Hex,"Hex")
#output to geojson for leafletR function below, delete file if exists
unlink("Hex.geojson")
writeOGR(Hex,"Hex.geojson","Hex", driver="GeoJSON")
#fisher natural break. +1 to last cutoff so that the max value will be colored.
#colorblind friendly colors from http://colorbrewer2.org/
hexVar="avgView"
n = 5
breakInt<-round(classIntervals(data.frame(Hex[,hexVar])[,1], n, style = "fisher")$brks)
breakInt[n+1]<-breakInt[n+1]+1
q.style <- styleGrad(prop=hexVar, breaks=breakInt,
style.val=c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c"),
leg="Average View",
fill.alpha=0.7, rad=8)
# create map
unlink("scf",recursive = TRUE)
q.map <- leaflet(data="Hex.geojson", title="scf", center=c(37.8044, -122.2708), zoom=12,
base.map="osm", style=q.style, popup="*")
#localMoran's I (beta)
#localM function defined in baseFunction.R
HexCount<-localM(Hex,"count")
HexView<-localM(Hex,"avgView")
HexComment<-localM(Hex,"avgComment")
HexVote<-localM(Hex,"avgVote")
#merge the localM values
HexTemp2<-data.frame(HexCount$hexNumber,HexCount$mType,HexView$mType,HexComment$mType,HexVote$mType)
names(HexTemp2)<-c("hexNumber","LM_count","LM_avgView","LM_avgComment","LM_avgVote")
Hex_localM<-merge(Hex,HexTemp2,by="hexNumber")
#output to geojson, delete file if exists
unlink("Hex_localM.geojson")
writeOGR(Hex_localM,"Hex_localM.geojson","Hex_localM", driver="GeoJSON")
q.styleLocalM <- styleCat(prop="LM_avgView", c("None","LH","LL","HL","HH"),
style.val=c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c"),
leg="Local Morans I",
fill.alpha=0.7, rad=8)
# create map
unlink("scf_localM",recursive = TRUE)
q.map <- leaflet(data="Hex_localM.geojson", title="scf localM", center=c(37.8044, -122.2708), zoom=12,
base.map="osm", style=q.styleLocalM, popup="*")
q.map <- leaflet(data="baseHex.geojson", title="baseHex", center=c(37.8044, -122.2708), zoom=12,
base.map="osm")
